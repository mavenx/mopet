\chapter{Introduction}

You know the problem: You are on a sightseeing-trep in a city and want to take a picture of some
building or just a nice place. But there are annoying persons moving around in front
of the object!

So why don't you use our MOPET Software?
All you need is a series of about 10 pictures of the object. The software 
detects all moving persons and objects and removes them.



\chapter{Methods}

Unfortunately, we did not find any papers or other literature to this topic. Most of the methods for estimating
background are using a video stream as input and estimate the optical flow.
We decided to use a series of images,
because the quality of a single picture is much better than the quality of a frame in a video.

In a series of images it is very difficult to estimate the optical flow, because the time between
two images is very much longer, than in a video stream.

Therefore, we came up with our own idea.

\section{Registration of images}

We don't assume that the series of pictures are taken using a tripod.
Because of small movements of the camera during a continuous shooting, the image section may move
around.
Therefore, we need to align the images with the following steps.

\begin{itemize}
 \item Applying a feature-detector to all images and calculating feature descriptors.
  As a feature-detector we used FAST and for the descriptor SURF.
 \item The feature-descriptors of all images are matched to the features of the first image.
 \item RANSAC is used to estimate a homography, which is robust against outliers due to moving foreground.
 \item All images are then warped, to the position of the first image.
\end{itemize}



\section{Foreground/Background Classification}

To classify between moving Foreground and static Background, we developed our own method called
``Minimum Variance Classifier''.

We are using the following assumptions to distinguish between foreground and background.

\begin{itemize}
 \item Moving Foreground leads to different pixel values at one position (x,y).
 \item Static background should lead to very similar pixel values.
 \item Therefore, the variance of the background pixels should be lower than the variance of the foreground.
\end{itemize}
 
First, we perform a gaussian filtering to reduce the influence of noise. For this purpose a sigma
of around 3 to 6 lead to the best performance. A too small sigma would not sufficiently suppress noise,
and a too large sigma would not lead to a accurate estimation of foreground and background.

We iterate through all (x,y) positions and the n gray values of the n input pictures.
We sort the n pixel according to the their gray value.
Now we iterate through all possible groups of neighbouring(after sorting) pixels.

e.g.:
\begin{itemize}
 \item pixels 1-2
 \item pixels 1-3
 \item pixels 1-4
 \item pixels 2-3
 \item pixels 2-4
 \item ....
\end{itemize}

For each group of pixel $\Omega$ we calculate the following cost function:

$$
f(\Omega) = var\{R(\Omega)\} + var\{G(\Omega)\} + var\{B(\Omega)\} + \frac{\alpha}{length\{\Omega\}}
$$

$R(\Omega)$, $G(\Omega)$ and $B(\Omega)$ are the pixel values of the red, green and blue channel
of the group. $length\{\Omega\}$ is the number of pixels in a group. $\alpha$ is a tuning parameter.
Finally, the group with the smallest function value is classified as background, and all
other pixels are classified as moving foreground.

Since we are minimizing this cost function, we are minimizing the variance of the pixel values.



\chapter{Implementation}

We implemented the algorithm in C++ with OpenCV.

\chapter{Evaluation / Results}







